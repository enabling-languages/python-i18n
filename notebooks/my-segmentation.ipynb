{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text segmentation: Myanmar (မြန်မာစာ) example\n",
    "\n",
    "Tokenisation, also known as break iteration or text segmentation, is a key step in Natural Language Processinng, lexiographic analysis, text layout and many other text based processes. Many NLP libraries and other packages provide tokenisation support for a key set of languages. Although, it may be necessary to use more specialist tools, depending on the language or script (writing system) being processed.\n",
    "\n",
    "Text segmentation or tokenisation can occur at codepoint, grapheme, syllable (phonemic or orthographic), word, line or sentence boundaries.\n",
    "\n",
    "For this example we will be looking at grapheme, syllable and word segmentation of Myanmar (Burmese) text. Like a number of other writing systems, Myanmar does not use whitespace to seperate words. Whitespace is used at phrasal and sentence boundaries, and within a phrase words run together without any indication of a boundary.\n",
    "\n",
    "Ideal tokenisation and line breaking for Myanmar text occurs at word boundaries, but identification of word boundaries requires a dictionary lookup or language specific tokenisation tools. A secondary break iteration point is at syllable boundaries. We will use a mix of language specific and generic tools to illustrate Myanmar segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "libpaths = [os.path.expanduser('../utils'), os.path.expanduser('../data/rbbi')]\n",
    "for libpath in libpaths:\n",
    "    if libpath not in sys.path:\n",
    "        sys.path.append(libpath)\n",
    "from elle import uu\n",
    "import el_utils as elu\n",
    "\n",
    "import pyidaungsu as pds\n",
    "from myanmar.encodings import UnicodeEncoding\n",
    "from myanmar.language import MorphoSyllableBreak, PhonemicSyllableBreak\n",
    "from icu import BreakIterator, Locale, RuleBasedBreakIterator\n",
    "import grapheme\n",
    "import regex as re\n",
    "\n",
    "\n",
    "LANG = \"my-MM\"\n",
    "LOC = Locale.createCanonical(LANG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_breaks(text, break_iterator):\n",
    "    break_iterator.setText(text)\n",
    "    lastpos = 0\n",
    "    while True:\n",
    "        next_boundary = break_iterator.nextBoundary()\n",
    "        if next_boundary == -1: return\n",
    "        yield text[lastpos:next_boundary]\n",
    "        lastpos = next_boundary\n",
    "\n",
    "# pymyan=True, the python-myanmar module is being used\n",
    "SEP = \"\\u2009·\\u2009\"\n",
    "def results(l, sep=\"|\", pymyan=False):\n",
    "    print(\"Number of tokens: \", str(len(l)))\n",
    "    r = sep.join(list(s['syllable'] for s in l)) if pymyan else sep.join(l)\n",
    "    print(\"Segmentation boundaries: \" + r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test string\n",
    "\n",
    "We will use the string __ရန်ကုန်ကွန်ပျူတာတက္ကသိုလ်__ (University of Computer Studies, Yangon) which should ideally resolve to three words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String: ရန်ကုန်ကွန်ပျူတာတက္ကသိုလ်\n",
      "Codepoints: U+101B U+1014 U+103A U+1000 U+102F U+1014 U+103A U+1000 U+103D U+1014 U+103A U+1015 U+103B U+1030 U+1010 U+102C U+1010 U+1000 U+1039 U+1000 U+101E U+102D U+102F U+101C U+103A\n",
      "+-------------+---------+\n",
      "| Component   |   Count |\n",
      "+=============+=========+\n",
      "| Characters  |      25 |\n",
      "+-------------+---------+\n",
      "| Bytes       |      75 |\n",
      "+-------------+---------+\n",
      "| Graphemes   |      14 |\n",
      "+-------------+---------+\n"
     ]
    }
   ],
   "source": [
    "s = \"ရန်ကုန်ကွန်ပျူတာတက္ကသိုလ်\"  # University of Computer Studies, Yangon\n",
    "uu(s, LANG).lengthData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using pyidaungsu package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uni\n",
      "['ရန်', 'ကုန်', 'ကွန်', 'ပျူ', 'တာ', 'တက္က', 'သိုလ်']\n",
      "['ရန်ကုန်', 'ကွန်ပျူတာ', 'တက္ကသိုလ်']\n"
     ]
    }
   ],
   "source": [
    "# Using pyidaungsu\n",
    "\n",
    "print(pds.detect(s))\n",
    "# syllable level\n",
    "print(pds.tokenize(s)) # lang parameter for default function is 'mm'\n",
    "#print(pds.tokenize(s, lang=\"mm\")) \n",
    "# word level \n",
    "print(pds.tokenize(s, form=\"word\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grapheme segmentation\n",
    "\n",
    "We will illustrate three approaches to grapheme segmentation:\n",
    "\n",
    "1. A regular expression using the the _[regex](https://github.com/mrabarnett/mrab-regex)_ package with the regex pattern `r'\\X'`. _Regex_ does not support language specific tailoring for text segmentation.\n",
    "2. The _[grapheme](https://github.com/alvinlindstam/grapheme)_ package for working with user perceived characters. It implements [Unicode Standard Annex #29](http://unicode.org/reports/tr29/). _Grapheme_ does not support language specific tailoring for text segmentation.\n",
    "3. _[PyICU](https://gitlab.pyicu.org/main/pyicu)'s_ `BreakIterator.createCharacterInstance()`. _PyICU_ is a Python extension wrapping the ICU C/C++ libraries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens:  14\n",
      "Segmentation boundaries: ရ · န် · ကု · န် · ကွ · န် · ပျူ · တ · ာ · တ · က္ · က · သို · လ်\n"
     ]
    }
   ],
   "source": [
    "chars_regex = re.findall(r'\\X', s)\n",
    "results(chars_regex, sep=SEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grapheme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the time of writing, grapheme supports Unicode 13.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens:  14\n",
      "Segmentation boundaries: ရ · န် · ကု · န် · ကွ · န် · ပျူ · တ · ာ · တ · က္ · က · သို · လ်\n"
     ]
    }
   ],
   "source": [
    "# Graphemes\n",
    "chars_grapheme = list(grapheme.graphemes(s))\n",
    "results(chars_grapheme, sep=SEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyICU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens:  14\n",
      "Segmentation boundaries: ရ · န် · ကု · န် · ကွ · န် · ပျူ · တ · ာ · တ · က္ · က · သို · လ်\n"
     ]
    }
   ],
   "source": [
    "cbi = BreakIterator.createCharacterInstance(LOC)\n",
    "chars_icu = list(iterate_breaks(s, cbi))\n",
    "\n",
    "results(chars_icu, sep=SEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syllable segmentation\n",
    "\n",
    "Three options are available for syllable segementation:\n",
    "\n",
    "1. PyICU using rule based break iteration.\n",
    "2. Two Myanmar specific packages:\n",
    "    1. [pyidaungsu](https://github.com/kaunghtetsan275/pyidaungsu). Pyidaungsu provides syllable level segmentation for Myanmar(Burmese), S'gaw Karen, Shan and Mon.\n",
    "    2. [python-myanmar](https://github.com/trhura/python-myanmar). This package provides both morphological and phonetic syllable breaks for Myanmar (Burmese) text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyICU\n",
    "\n",
    "_PyICU_ does not provide a syllable based break iterator, but it is possible to write a custom rule set for the break iterator which would perform syllable level segmentation.\n",
    "\n",
    "We are using `MyanmarSyllable.rbbi` from the [Lucene](https://github.com/apache/lucene/blob/main/lucene/analysis/icu/src/data/uax29/MyanmarSyllable.rbbi) project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens:  8\n",
      "Segmentation boundaries: ရန် · ကုန် · ကွန် · ပျူ · တာ · တ · က္က · သိုလ်\n"
     ]
    }
   ],
   "source": [
    "with open('../data/rbbi/MyanmarSyllable.rbbi') as f:\n",
    "    rbbi = f.read()\n",
    "\n",
    "sbi = RuleBasedBreakIterator(rbbi)\n",
    "syl_icu = list(iterate_breaks(s, sbi))  \n",
    "results(syl_icu, sep=SEP)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pyidaungsu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens:  7\n",
      "Segmentation boundaries: ရန် · ကုန် · ကွန် · ပျူ · တာ · တက္က · သိုလ်\n"
     ]
    }
   ],
   "source": [
    "syl_pyidaungsu = pds.tokenize(s)\n",
    "# pds.tokenize() can take a lang parameter, which defaults to 'mm'\n",
    "# i.e. pds.tokenize(s, lang=\"mm\")\n",
    "\n",
    "results(syl_pyidaungsu, sep=SEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python-myanmar\n",
    "\n",
    "The python-myanmar module supports both phonemic and morphological syllables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens:  8\n",
      "Segmentation boundaries: ရန် · ကုန် · ကွန် · ပျူ · တာ · တက္ · က · သိုလ်\n",
      "Number of tokens:  12\n",
      "Segmentation boundaries: ရ · န် · ကု · န် · ကွ · န် · ပျူ · တာ · တ · က္က · သို · လ်\n"
     ]
    }
   ],
   "source": [
    "# Myanmar (Burmese) phonemic syllables - using python-myanmar\n",
    "syl_py_myan_phonemic = list(PhonemicSyllableBreak(s, UnicodeEncoding()))\n",
    "results(syl_py_myan_phonemic, pymyan=True, sep=SEP)\n",
    "\n",
    "# Myanmar (Burmese) morphological syllables - using python-myanmar\n",
    "syl_py_myan_morpho = list(MorphoSyllableBreak(s, UnicodeEncoding()))\n",
    "results(syl_py_myan_morpho, pymyan=True, sep=SEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Various regular expression syllabification expressions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens:  7\n",
      "Segmentation boundaries: ရန် · ကုန် · ကွန် · ပျူ · တာ · တက္က · သိုလ်\n"
     ]
    }
   ],
   "source": [
    "def parse_regex(text, pattern):\n",
    "    r = re.sub(pattern, r\"·\\1\", text)\n",
    "    if r[0] == \"·\":\n",
    "        r = r[1:]\n",
    "    return r.split(\"·\")\n",
    "\n",
    "# Regex pattern from ReSegment: https://github.com/swanhtet1992/ReSegment\n",
    "resegment_pattern = r'(?:(?<!္)([က-ဪဿ၊-၏]|[၀-၉]+|[^က-၏]+)(?![ှျ]?[့္်]))'\n",
    "syl_resegment = parse_regex(s, resegment_pattern)\n",
    "results(syl_resegment, sep=SEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variation in syllable algorithms\n",
    "\n",
    "\n",
    "\n",
    "|Technique  |Count  |Segmentation |\n",
    "|---------- |------ |------------ |\n",
    "|ICU custom rules |8 |ရန် · ကုန် · ကွန် · ပျူ · တာ · တ · က္က · သိုလ် |\n",
    "|Pyidaungsu |7 |ရန် · ကုန် · ကွန် · ပျူ · တာ · တက္က · သိုလ် |\n",
    "|python-myanmar (phonemic) |8 |ရန် · ကုန် · ကွန် · ပျူ · တာ · တက္ · က · သိုလ် |\n",
    "|python-myanmar (morphological) |12 |ရ · န် · ကု · န် · ကွ · န် · ပျူ · တာ · တ · က္က · သို · လ် |\n",
    "|ReSegment |7 |ရန် · ကုန် · ကွန် · ပျူ · တာ · တက္က · သိုလ် |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyICU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens:  4\n",
      "Segmentation boundaries: ရန် · ကုန် · ကွန်ပျူတာ · တက္ကသိုလ်\n"
     ]
    }
   ],
   "source": [
    "wbi = BreakIterator.createWordInstance(LOC)\n",
    "words_icu = list(iterate_breaks(s, wbi))\n",
    "\n",
    "results(words_icu, sep=SEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pyidaungsu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens:  3\n",
      "Segmentation boundaries: ရန်ကုန် · ကွန်ပျူတာ · တက္ကသိုလ်\n"
     ]
    }
   ],
   "source": [
    "word_pyidaungsu = pds.tokenize(s, form=\"word\")\n",
    "\n",
    "results(word_pyidaungsu, sep=SEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variation in word segmentation algorithms\n",
    "\n",
    "|Technique  |Count  |Segmentation |\n",
    "|---------- |------ |------------ |\n",
    "|PyICU |4 |ရန် · ကုန် · ကွန်ပျူတာ · တက္ကသိုလ် |\n",
    "|Pyidaungsu |3 |ရန်ကုန် · ကွန်ပျူတာ · တက္ကသိုလ် |\n",
    "\n",
    "The ideal word segmentation for `s` would be `ရန်ကုန် · ကွန်ပျူတာ · တက္ကသိုလ်`, where __ရန်ကုန်__ is the endonym for the city Yangon.\n",
    "\n",
    "_ICU_ uses dictionary based method for Myanmar word segmentation, and the results are dependant on the quality fo the dictionary."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1089646a020cfe6092fafe876ee4a6e68b3ec5a13ed8a22b79c0a42e9e2a954f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit ('el': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
